{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth of Anesthesia Classification - Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.tabularNN import TabularNN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from src.dataset.eeg_dataset import EEGDataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from tabicl import TabICLClassifier\n",
    "from pathlib import Path\n",
    "from src.utils import Utils\n",
    "from tabpfn import TabPFNClassifier\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [1, 2, 5, 10, 30, 60]\n",
    "step_sizes = [1, 2, 5, 10, 30, 60]\n",
    "strategy = \"FeatureBased\"\n",
    "timing = 60  # window_sizes[5]\n",
    "sampling_rate = 128\n",
    "window_size = sampling_rate * timing\n",
    "step_size = sampling_rate * timing\n",
    "preprocessing = True\n",
    "feature_selection = True\n",
    "depth_of_anesthesia = True\n",
    "random_seed = 42\n",
    "for_majority = int(window_size / 2)\n",
    "number_of_features = 50\n",
    "base_path = Path.cwd()\n",
    "data_path = base_path / \"EEG_data\" / \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"You are using {strategy} with a window size of {window_size} and step size of {step_size} to predict Depth of Anesthesia\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load the Data and create the features\n",
    "If your feature-dataset was already created and saved as a csv, you can skip to Step 4\n",
    "\n",
    "Assign your patients/volunteers to the appropriate training/validation or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = EEGDataset(\n",
    "    data_dir=base_path / \"EEG_data\",\n",
    "    training_ids=[\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        6,\n",
    "        7,\n",
    "        12,\n",
    "    ],\n",
    "    validation_ids=[11, 10, 9],\n",
    "    testing_ids=[8, 5],\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    sampling_rate=sampling_rate,\n",
    "    majority_voting=True,\n",
    "    for_majority=for_majority,\n",
    "    preprocessing=preprocessing,\n",
    "    inference_mode=False,\n",
    "    depth_of_anesthesia=depth_of_anesthesia,\n",
    "    strategy=strategy,\n",
    ")\n",
    "training_data = eeg_data.train_df\n",
    "test_data = eeg_data.test_df\n",
    "validation_data = eeg_data.val_df\n",
    "training_data.to_csv(\n",
    "    data_path / f\"training_data_{window_size}_{step_size}.csv\", index=False\n",
    ")\n",
    "test_data.to_csv(data_path / f\"test_data_{window_size}_{step_size}.csv\", index=False)\n",
    "validation_data.to_csv(\n",
    "    data_path / f\"validation_data_{window_size}_{step_size}.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Read in the saved csv-feature set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(data_path / f\"training_data_{window_size}_{step_size}.csv\")\n",
    "test_data = pd.read_csv(data_path / f\"test_data_{window_size}_{step_size}.csv\")\n",
    "validation_data = pd.read_csv(\n",
    "    data_path / f\"validation_data_{window_size}_{step_size}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in training_data.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Datasets get prepared and preprocessed for the different binary classification targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = Utils(\n",
    "    for_majority=for_majority,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    random_seed=random_seed,\n",
    "    preprocessing=preprocessing,\n",
    "    sampling_rate=sampling_rate,\n",
    "    results_validation_csv_path=base_path\n",
    "    / \"doA_classification\"\n",
    "    / \"ml_models\"\n",
    "    / f\"{strategy}_validation_results_df.csv\",\n",
    "    results_test_csv_path=base_path\n",
    "    / \"doA_classification\"\n",
    "    / \"ml_models\"\n",
    "    / f\"{strategy}_test_results_df.csv\",\n",
    "    model_dir=base_path / \"doA_classification\" / \"ml_models\",\n",
    ")\n",
    "exclude_columns = [\"Start\", \"End\", \"sleep\"]\n",
    "labels = [\"sleep\"]\n",
    "if depth_of_anesthesia:\n",
    "    exclude_columns.extend([\"cr\", \"sspl\", \"burst_suppression\"])\n",
    "    labels_to_process = [\"sleep\", \"cr\", \"sspl\", \"burst_suppression\"]\n",
    "    labels.extend([\"cr\", \"sspl\", \"burst_suppression\"])\n",
    "else:\n",
    "    labels_to_process = [\"sleep\"]\n",
    "\n",
    "# Define features (excluding the necessary columns)\n",
    "features = training_data.drop(columns=exclude_columns, errors=\"ignore\").columns\n",
    "\n",
    "# Create a new dictionary to store preprocessed data\n",
    "preprocessed_data_dict = {}\n",
    "\n",
    "for label in labels_to_process:\n",
    "    print(f\"Processing {label}...\")\n",
    "    # Preprocess data\n",
    "    (\n",
    "        X,\n",
    "        y,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        train_loader_nn,\n",
    "        val_loader_nn,\n",
    "        test_loader_nn,\n",
    "        input_size,\n",
    "    ) = utils.preprocess_data(\n",
    "        X=training_data[features],\n",
    "        y=training_data[label],\n",
    "        X_val=validation_data[features],\n",
    "        y_val=validation_data[label],\n",
    "        X_test=test_data[features],\n",
    "        y_test=test_data[label],\n",
    "        k=number_of_features,\n",
    "        batch_size=16,\n",
    "        device=\"mps\",\n",
    "        strategy=strategy,\n",
    "        classification_type=label,\n",
    "        feature_selection=True,\n",
    "    )\n",
    "\n",
    "    preprocessed_data_dict[label] = {\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        \"X_val\": X_val,\n",
    "        \"y_val\": y_val,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"train_loader_nn\": train_loader_nn,\n",
    "        \"val_loader_nn\": val_loader_nn,\n",
    "        \"test_loader_nn\": test_loader_nn,\n",
    "        \"input_size\": input_size,\n",
    "    }\n",
    "\n",
    "print(\"Processing completed for all labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Define ML-Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=random_seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed(random_seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "models = {\n",
    "    \"TabICLClassifier\": TabICLClassifier(random_state=42, device=device),\n",
    "    \"CatBoostClassifier\": CatBoostClassifier(verbose=0, random_state=random_seed),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=random_seed),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"TabPFNClassifier\": TabPFNClassifier(\n",
    "        random_state=42, device=device, ignore_pretraining_limits=True\n",
    "    ),\n",
    "    \"TabularNN\": TabularNN(\n",
    "        input_size=input_size, hidden_sizes=[input_size, 32, 16], dropout_rate=0.4\n",
    "    ).to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Models for the different binary classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [\"sleep\", \"sspl\", \"cr\", \"burst_suppression\"]:\n",
    "    for model_name, model in models.items():\n",
    "        utils.train_and_evaluate_model(\n",
    "            name=model_name,\n",
    "            model=model,\n",
    "            train_loader_nn=preprocessed_data_dict[label][\"train_loader_nn\"],\n",
    "            val_loader_nn=preprocessed_data_dict[label][\"val_loader_nn\"],\n",
    "            X=preprocessed_data_dict[label][\"X\"],\n",
    "            y=preprocessed_data_dict[label][\"y\"],\n",
    "            X_val=preprocessed_data_dict[label][\"X_val\"],\n",
    "            y_val=preprocessed_data_dict[label][\"y_val\"],\n",
    "            skf=StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed),\n",
    "            classification_type=label,\n",
    "            strategy=strategy,\n",
    "            number_of_features=number_of_features,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Get Test Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [\"sleep\", \"sspl\", \"cr\", \"burst_suppression\"]:\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        test_results = utils.evaluate_model_on_test(\n",
    "            model_name=model_name,\n",
    "            model=model,\n",
    "            X_test=preprocessed_data_dict[label][\"X_test\"],\n",
    "            y_test=preprocessed_data_dict[label][\"y_test\"],\n",
    "            test_loader=preprocessed_data_dict[label][\"test_loader_nn\"],\n",
    "            classification_type=label,\n",
    "            strategy=strategy,\n",
    "            number_of_features=number_of_features,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
