{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.tabularNN import TabularNN\n",
    "import os\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from src.dataset.eeg_dataset import EEGDataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from tabicl import TabICLClassifier\n",
    "import json\n",
    "from src.utils import Utils\n",
    "import timeit\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.inference.inference import EEGInference\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from lime import lime_tabular\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the Parameters the same way as they were defined in the training process\n",
    "and define the paths accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [1, 2, 5, 10, 30, 60]\n",
    "step_sizes = [1, 2, 5, 10, 30, 60]\n",
    "strategy = \"FeatureBased\"  # \"rawEEG\"\n",
    "timing = window_sizes[5]\n",
    "sampling_rate = 128\n",
    "window_size = sampling_rate * timing\n",
    "step_size = sampling_rate * timing\n",
    "preprocessing = True\n",
    "feature_selection = True\n",
    "num_selected_features = 50\n",
    "depth_of_anesthesia = True\n",
    "random_seed = 42\n",
    "for_majority = int(window_size / 2)\n",
    "sampling_rate = 128\n",
    "base_path = Path.cwd()\n",
    "data_path = base_path / \"src\" / \"dataset\" / \"saved_data\"\n",
    "volunteer_number = \"5-3\"  #Choose a specific volunteer\n",
    "case_number = \"5_3\"  \n",
    "print(base_path)\n",
    "data_path = base_path / \"EEG_data\" / \"Session3\" / f\"Case_{case_number}\"\n",
    "file_path = base_path.parent.parent.parent / \"Ablation\" / \"final\"\n",
    "selected_features_path = file_path / \"selected_features\"\n",
    "scaler_path = file_path / \"scaler\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Function for defining file paths\n",
    "\n",
    "If you want to run the NN, you need to change the file extensions to .pt instead of .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_file_paths(\n",
    "    window_size,\n",
    "    step_size,\n",
    "    majority,\n",
    "    data_path,\n",
    "    file_path,\n",
    "    model_names,\n",
    "    volunteer_number,\n",
    "    case_number,\n",
    "    number_of_selected_feature=None,\n",
    "    selected_features_path=None,\n",
    "    random_seed=42,\n",
    "):\n",
    "    \"\"\"Define file paths for models, data, and other resources.\n",
    "    Args:\n",
    "        window_size (int): Size of the window for analysis.\n",
    "        step_size (int): Step size for moving the window.\n",
    "        majority (int): Majority voting parameter.\n",
    "        data_path (Path): Path to the data directory.\n",
    "        file_path (Path): Path to the model directory.\n",
    "        model_names (dict): Dictionary containing model names for different tasks.\n",
    "        volunteer_number (str): Identifier for the volunteer.\n",
    "        case_number (str): Identifier for the case of that volunteer.\n",
    "        number_of_selected_feature (int, optional): Number of selected features. Defaults to None.\n",
    "        selected_features_path (Path, optional): Path to selected features directory. Defaults to None.\n",
    "        random_seed (int, optional): Random seed for reproducibility. Defaults to 42.\n",
    "    Returns:\n",
    "        tuple: Contains paths and filenames for models, data, and other resources.\n",
    "    \"\"\"\n",
    "\n",
    "    csv_file = data_path / f\"prop_{case_number}eeg_Fp1Fp2.csv\"\n",
    "    propofol_concentration_blood_plasma = pd.read_csv(\n",
    "        base_path\n",
    "        / \"EEG_data\"\n",
    "        / \"propofol_infusion\"\n",
    "        / f\"prop{volunteer_number}Ce_Fp1Fp2.csv\"\n",
    "    )\n",
    "    csv_files_groundtruth = {\n",
    "        \"sleep\": data_path / f\"prop{volunteer_number}sleep_Fp1Fp2.csv\",\n",
    "        \"bs1sec\": data_path / f\"prop{volunteer_number}bs1sec_Fp1Fp2.csv\",\n",
    "        \"bs3sec\": data_path / f\"prop{volunteer_number}bs3sec_Fp1Fp2.csv\",\n",
    "        \"cr\": data_path / f\"prop{volunteer_number}cr_Fp1Fp2.csv\",\n",
    "        \"sspl\": data_path / f\"prop{volunteer_number}sspl_Fp1Fp2.csv\",\n",
    "    }\n",
    "    if number_of_selected_feature is not None:\n",
    "\n",
    "        model_filenames = {\n",
    "            \"sleep\": file_path\n",
    "            / f\"{strategy}_sleep_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['sleep']}_preprocTrue_randomseed{random_seed}_{number_of_selected_feature}.pkl\",\n",
    "            \"cr\": file_path\n",
    "            / f\"{strategy}_cr_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['cr']}_preprocTrue_randomseed{random_seed}_{number_of_selected_feature}.pkl\",\n",
    "            \"sspl\": file_path\n",
    "            / f\"{strategy}_sspl_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['sspl']}_preprocTrue_randomseed{random_seed}_{number_of_selected_feature}.pkl\",\n",
    "            \"burst_suppression\": file_path\n",
    "            / f\"{strategy}_burst_suppression_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['burst_suppression']}_preprocTrue_randomseed{random_seed}_{number_of_selected_feature}.pkl\",\n",
    "        }\n",
    "\n",
    "        selected_features_filename = {\n",
    "            \"sleep\": selected_features_path\n",
    "            / f\"Sleep_FeatureBased_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.json\",\n",
    "            \"cr\": selected_features_path\n",
    "            / f\"cr_FeatureBased_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.json\",\n",
    "            \"sspl\": selected_features_path\n",
    "            / f\"sspl_FeatureBased_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.json\",\n",
    "            \"burst_suppression\": selected_features_path\n",
    "            / f\"burst_suppression_FeatureBased_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.json\",\n",
    "        }\n",
    "        scaler_filenames = {\n",
    "            \"sleep\": scaler_path\n",
    "            / f\"FeatureBased_sleep_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.joblib\",\n",
    "            \"cr\": scaler_path\n",
    "            / f\"FeatureBased_cr_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.joblib\",\n",
    "            \"sspl\": scaler_path\n",
    "            / f\"FeatureBased_sspl_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.joblib\",\n",
    "            \"burst_suppression\": scaler_path\n",
    "            / f\"FeatureBased_burst_suppression_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.joblib\",\n",
    "        }\n",
    "\n",
    "        return (\n",
    "            file_path,\n",
    "            csv_files_groundtruth,\n",
    "            model_filenames,\n",
    "            model_names,\n",
    "            selected_features_filename,\n",
    "            scaler_filenames,\n",
    "            csv_file,\n",
    "            propofol_concentration_blood_plasma,\n",
    "        )\n",
    "    else:\n",
    "        model_filenames = {\n",
    "            \"sleep\": file_path\n",
    "            / f\"{strategy}_sleep_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['sleep']}_preprocTrue_randomseed42_all.pt\",\n",
    "            \"cr\": file_path\n",
    "            / f\"{strategy}_cr_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['cr']}_preprocTrue_randomseed42_all.pt\",\n",
    "            \"sspl\": file_path\n",
    "            / f\"{strategy}_sspl_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['sspl']}_preprocTrue_randomseed42_all.pt\",\n",
    "            \"burst_suppression\": file_path\n",
    "            / f\"{strategy}_burst_suppression_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['burst_suppression']}_preprocTrue_randomseed42_all.pt\",\n",
    "        }\n",
    "\n",
    "        return (\n",
    "            file_path,\n",
    "            csv_files_groundtruth,\n",
    "            model_filenames,\n",
    "            model_names,\n",
    "            None,\n",
    "            None,\n",
    "            csv_file,\n",
    "            propofol_concentration_blood_plasma,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Define which model you would like to run the inference for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    \"sleep\": \"RandomForestClassifier\",\n",
    "    \"cr\": \"RandomForestClassifier\",\n",
    "    \"sspl\": \"RandomForestClassifier\",\n",
    "    \"burst_suppression\": \"RandomForestClassifier\",\n",
    "}\n",
    "\n",
    "\"\"\" \n",
    "Further Examples:\n",
    "model_names = {\n",
    "    \"sleep\": \"TabICLClassifier\",\n",
    "    \"cr\":  \"TabICLClassifier\",\n",
    "    \"sspl\": \"TabICLClassifier\",\n",
    "    \"burst_suppression\":  \"TabICLClassifier\",\n",
    "}\n",
    "\n",
    "model_names = {\n",
    "    \"sleep\": \"TabularNN\",\n",
    "    \"cr\":  \"TabularNN\",\n",
    "    \"sspl\": \"TabularNN\",\n",
    "    \"burst_suppression\":\"TabularNN\",\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Run the Inference:\n",
    "\n",
    "- If you don't have any ground truths, you can run the inference, by putting inference_mode to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "(\n",
    "    file_path,\n",
    "    csv_files_groundtruth,\n",
    "    model_filenames,\n",
    "    model_names,\n",
    "    selected_features_filename,\n",
    "    scaler_filenames,\n",
    "    csv_file,\n",
    "    propofol_concentration_blood_plasma,\n",
    ") = define_file_paths(\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    majority=for_majority,\n",
    "    number_of_selected_feature=num_selected_features,\n",
    "    data_path=data_path,\n",
    "    file_path=file_path,\n",
    "    model_names=model_names,\n",
    "    selected_features_path=selected_features_path,\n",
    "    volunteer_number=volunteer_number,\n",
    "    case_number=case_number,\n",
    "    random_seed=random_seed,\n",
    ")\n",
    "inference = EEGInference(\n",
    "    csv_file=csv_file,\n",
    "    sampling_rate=sampling_rate,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    for_majority=for_majority,\n",
    "    preprocessing=preprocessing,\n",
    "    majority_voting=True,\n",
    "    strategy=strategy,\n",
    "    random_seed=random_seed,\n",
    "    feature_selection=feature_selection,\n",
    "    scaler_applicable=False,\n",
    "    device=\"cpu\",\n",
    "    inference_mode=False,\n",
    "    depth_of_anesthesia=True,\n",
    "    visualize_results=True,\n",
    "    csv_files_groundtruth=csv_files_groundtruth,\n",
    "    model_filenames=model_filenames,\n",
    "    model_names=model_names,\n",
    "    selected_features_filename=selected_features_filename,\n",
    "    scaler_filenames=scaler_filenames,\n",
    "    propofol_concentration_blood_plasma=propofol_concentration_blood_plasma,\n",
    "    zoomed_in=True,\n",
    ")\n",
    "end = time.perf_counter()\n",
    "print(f\"Final Execution time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: If you want to run local error analysis with LIME for the TabICLClassifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.1 Define/adjust your file paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pickle, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager as fm\n",
    "import textwrap\n",
    "import matplotlib as mpl\n",
    "import textwrap\n",
    "\n",
    "utils = Utils(\n",
    "    for_majority=for_majority,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    random_seed=random_seed,\n",
    "    preprocessing=preprocessing,\n",
    "    sampling_rate=sampling_rate,\n",
    "    results_validation_csv_path=base_path\n",
    "    / \"doA_classification\"\n",
    "    / \"ml_models\"\n",
    "    / f\"{strategy}_validation_results_df.csv\",\n",
    "    results_test_csv_path=base_path\n",
    "    / \"doA_classification\"\n",
    "    / \"ml_models\"\n",
    "    / f\"{strategy}_test_results_df.csv\",\n",
    "    model_dir=base_path / \"doA_classification\" / \"ml_models\",\n",
    ")\n",
    "label = \"burst_suppression\"\n",
    "model_name = \"TabICLClassifier\"\n",
    "features = inference.features_processed\n",
    "predictions = inference.prediction\n",
    "\n",
    "base_path = Path.cwd()\n",
    "my_path = base_path.parent.parent.parent / \"Ablation\" / \"final\"\n",
    "model_path = (\n",
    "    my_path\n",
    "    / f\"FeatureBased_{label}_ws7680_ss7680_majority3840_typeTabICLClassifier_preprocTrue_randomseed42_50.pkl\"\n",
    ")\n",
    "selected_features_path = (\n",
    "    my_path\n",
    "    / f\"selected_features/{label}_FeatureBased_ws{window_size}_ss{step_size}_majority{for_majority}_preprocTrue_randomseed42_numfeatures50.json\"\n",
    ")\n",
    "training_data = pd.read_csv(\n",
    "    base_path / \"EEG_data\" / \"dataset\" / f\"training_data_{window_size}_{step_size}.csv\"\n",
    ")\n",
    "\n",
    "# --- 0) Load artifacts safely ---\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "\n",
    "if not os.path.exists(selected_features_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Selected-features file not found: {selected_features_path}\"\n",
    "    )\n",
    "\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(selected_features_path, \"r\") as f:\n",
    "    selected_feature_names = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Run LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Predict-proba wrapper (returns probs IN model.classes_ order) ---\n",
    "def predict_proba_lime(X, model=model):\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(1, -1)\n",
    "    probs = model.predict_proba(X)  # assumed to be in model.classes_ order\n",
    "    if probs.ndim != 2:\n",
    "        raise ValueError(\n",
    "            f\"predict_proba returned shape {probs.shape}, expected (n, n_classes)\"\n",
    "        )\n",
    "    if probs.shape[1] == 1:\n",
    "        # Binary edge-case: ensure two columns [p0, p1]\n",
    "        probs = np.hstack([1 - probs, probs])\n",
    "    return probs\n",
    "\n",
    "\n",
    "def preprocessing_lime(training_data, selected_feature_names, utils, predictions):\n",
    "    missing_cols = [c for c in selected_feature_names if c not in training_data.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"Missing features in training_data: {missing_cols}\")\n",
    "\n",
    "    X_train_raw = training_data.loc[:, selected_feature_names].copy()\n",
    "    X_test_raw = predictions.loc[:, selected_feature_names].copy()\n",
    "\n",
    "    # LIME/model should see the same preprocessing as training:\n",
    "    # Fill NaNs BEFORE scaling to avoid propagating nans through the scaler\n",
    "    X_train_raw = X_train_raw.fillna(0.0)\n",
    "    X_test_raw = X_test_raw.fillna(0.0)\n",
    "\n",
    "    # Apply the EXACT scaler used in training\n",
    "    X_train = X_train_raw.values\n",
    "    X_test = X_test_raw.values\n",
    "\n",
    "    # --- 2) Pretty feature names (must align with column order above) ---\n",
    "    pretty_feature_names = [\n",
    "        utils.feature_name_map.get(f, f) for f in selected_feature_names\n",
    "    ]\n",
    "\n",
    "    # --- 3) Class names MUST follow model.classes_ order ---\n",
    "    # Example mapping from numeric to display labels; adjust to your labels if needed\n",
    "    names_by_class = {0: \"no Burst Suppression\", 1: \"Burst Suppression\"}\n",
    "    try:\n",
    "        class_names_in_model_order = [names_by_class[c] for c in model.classes_]\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Could not build class names from model.classes_: {e}\")\n",
    "\n",
    "    # --- 5) Build LIME explainer on the EXACT representation the model sees ---\n",
    "    explainer = LimeTabularExplainer(\n",
    "        training_data=X_train,  # scaled data (same space as model)\n",
    "        mode=\"classification\",\n",
    "        feature_names=pretty_feature_names,  # aligned with selected_feature_names order\n",
    "        class_names=class_names_in_model_order,\n",
    "        discretize_continuous=True,\n",
    "        random_state=42,\n",
    "    )\n",
    "    return (\n",
    "        explainer,\n",
    "        X_test,\n",
    "        pretty_feature_names,\n",
    "        class_names_in_model_order\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_lime_topk(\n",
    "    exp,\n",
    "    label_idx,\n",
    "    pos_class_name,\n",
    "    neg_class_name,\n",
    "    top_k=7,\n",
    "    pred_proba=None,  # if None, will use exp.predict_proba[label_idx]\n",
    "    wrap_width=30,\n",
    "):\n",
    "    # --- sanity guards ---\n",
    "    avail = set(exp.available_labels())\n",
    "    if label_idx not in avail:\n",
    "        raise ValueError(\n",
    "            f\"label_idx {label_idx} not in exp.available_labels()={sorted(avail)}\"\n",
    "        )\n",
    "    if pred_proba is None:\n",
    "        pred_proba = float(exp.predict_proba[label_idx])\n",
    "    # Optional: warn if top label differs\n",
    "    top_from_exp = int(np.argmax(exp.predict_proba))\n",
    "    if top_from_exp != label_idx:\n",
    "        print(\n",
    "            f\"[warn] label_idx={label_idx} != argmax(exp.predict_proba)={top_from_exp}\"\n",
    "        )\n",
    "\n",
    "    # ---- LIME pairs for this label ----\n",
    "    pairs = exp.as_list(label=label_idx)\n",
    "    feat_labels = np.array([p[0] for p in pairs])\n",
    "    weights = np.array([p[1] for p in pairs], dtype=float)\n",
    "\n",
    "    # sort by |w|, keep top_k, strongest at top\n",
    "    order = np.argsort(np.abs(weights))[::-1][:top_k]\n",
    "    feat_labels = feat_labels[order][::-1]\n",
    "    weights = weights[order][::-1]\n",
    "\n",
    "    # optional wrap\n",
    "    if wrap_width:\n",
    "        feat_labels = np.array(\n",
    "            [\"\\n\".join(textwrap.wrap(lbl, width=wrap_width)) for lbl in feat_labels]\n",
    "        )\n",
    "\n",
    "    # ---- figure sizing ----\n",
    "    SINGLE_COL_W_IN = 10\n",
    "    HEIGHT = 5\n",
    "\n",
    "    mpl.rcParams.update(\n",
    "        {\n",
    "            \"font.family\": \"serif\",\n",
    "            \"font.serif\": [\n",
    "                \"Times New Roman\",\n",
    "                \"Times\",\n",
    "                \"Nimbus Roman No9 L\",\n",
    "                \"DejaVu Serif\",\n",
    "            ],\n",
    "            \"font.size\": 17,\n",
    "            \"axes.labelsize\": 20,\n",
    "            \"xtick.labelsize\": 20,\n",
    "            \"ytick.labelsize\": 20,\n",
    "            \"legend.fontsize\": 20,\n",
    "            \"axes.linewidth\": 0.8,\n",
    "            \"pdf.fonttype\": 42,\n",
    "            \"ps.fonttype\": 42,\n",
    "            \"text.usetex\": False,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(SINGLE_COL_W_IN, HEIGHT))\n",
    "    y = np.arange(len(feat_labels))\n",
    "    pos_mask = weights >= 0  # supports explained class\n",
    "    neg_mask = ~pos_mask\n",
    "\n",
    "    ax.barh(\n",
    "        y[pos_mask],\n",
    "        weights[pos_mask],\n",
    "        color=\"0.7\",\n",
    "        edgecolor=\"grey\",\n",
    "        linewidth=0.3,\n",
    "        label=pos_class_name,\n",
    "    )\n",
    "    ax.barh(\n",
    "        y[neg_mask],\n",
    "        weights[neg_mask],\n",
    "        color=\"0.5\",\n",
    "        edgecolor=\"grey\",\n",
    "        linewidth=0.3,\n",
    "        hatch=\"//\",\n",
    "        label=neg_class_name,\n",
    "    )\n",
    "\n",
    "    ax.axvline(0, linewidth=0.7)\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(feat_labels)\n",
    "    ax.set_xlabel(\"Contribution (LIME weight)\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer, X_test,pretty_feature_names,class_names_in_model_order = preprocessing_lime(training_data, selected_feature_names, utils, predictions)\n",
    "\n",
    "features_new = pd.DataFrame(X_test, columns=pretty_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 156 # Decide which window you would like to look at\n",
    "probs_row = model.predict_proba(X_test[sample].reshape(1, -1))[0]\n",
    "label_idx = int(np.argmax(probs_row)) \n",
    "exp = explainer.explain_instance(\n",
    "    data_row=features_new.iloc[\n",
    "        sample\n",
    "    ].values,  \n",
    "    predict_fn=predict_proba_lime,\n",
    "    num_features=5,\n",
    "    labels=[label_idx],  \n",
    ")\n",
    "\n",
    "pairs = exp.as_list(label=label_idx)\n",
    "\n",
    "print(\"model.classes_:\", model.classes_)\n",
    "print(\"Explaining label idx:\", label_idx, \"->\", class_names_in_model_order[label_idx])\n",
    "for f, w in pairs:\n",
    "    print(f\"{f:>40s}: {w:+.3f}\")\n",
    "\n",
    "exp.show_in_notebook(show_table=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_lime_topk(\n",
    "    exp,\n",
    "    label_idx=label_idx,\n",
    "    top_k=5,  # how many features to show\n",
    "    pos_class_name=\"Burst Suppression\",\n",
    "    neg_class_name=\"No Burst Suppression\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
