{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.tabularNN import TabularNN\n",
    "import os\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from src.dataset.eeg_dataset import EEGDataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from tabicl import TabICLClassifier\n",
    "import json\n",
    "from src.utils import Utils\n",
    "import timeit\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.inference.inference import EEGInference\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from lime import lime_tabular\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the Parameters the same way as they were defined in the training process\n",
    "and define the paths accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [1, 2, 5, 10, 30, 60]\n",
    "step_sizes = [1, 2, 5, 10, 30, 60]\n",
    "strategy = \"FeatureBased\"  # \"rawEEG\"\n",
    "timing = window_sizes[5]\n",
    "sampling_rate = 128\n",
    "window_size = sampling_rate * timing\n",
    "step_size = sampling_rate * timing\n",
    "preprocessing = True\n",
    "feature_selection = True\n",
    "num_selected_features = 50\n",
    "depth_of_anesthesia = True\n",
    "random_seed = 42\n",
    "for_majority = int(window_size / 2)\n",
    "sampling_rate = 128\n",
    "base_path = Path.cwd()\n",
    "data_path = base_path / \"src\" / \"dataset\" / \"saved_data\"\n",
    "volunteer_number = \"5-3\"  # \"8-2\"  # Choose a specific volunteer\n",
    "case_number = \"5_3\"  # \"8_2\"\n",
    "print(base_path)\n",
    "data_path = base_path / \"EEG_data\" / \"Session3\" / f\"Case_{case_number}\"\n",
    "file_path = base_path.parent.parent.parent / \"Ablation\" / \"final\"\n",
    "selected_features_path = file_path / \"selected_features\"\n",
    "scaler_path = file_path / \"scaler\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Function for defining file paths\n",
    "\n",
    "If you want to run the NN, you need to change the file extensions to .pt instead of .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_file_paths(\n",
    "    window_size,\n",
    "    step_size,\n",
    "    majority,\n",
    "    data_path,\n",
    "    file_path,\n",
    "    model_names,\n",
    "    volunteer_number,\n",
    "    case_number,\n",
    "    number_of_selected_feature=None,\n",
    "    selected_features_path=None,\n",
    "    random_seed=42,\n",
    "):\n",
    "    \"\"\"Define file paths for models, data, and other resources.\n",
    "    Args:\n",
    "        window_size (int): Size of the window for analysis.\n",
    "        step_size (int): Step size for moving the window.\n",
    "        majority (int): Majority voting parameter.\n",
    "        data_path (Path): Path to the data directory.\n",
    "        file_path (Path): Path to the model directory.\n",
    "        model_names (dict): Dictionary containing model names for different tasks.\n",
    "        volunteer_number (str): Identifier for the volunteer.\n",
    "        case_number (str): Identifier for the case of that volunteer.\n",
    "        number_of_selected_feature (int, optional): Number of selected features. Defaults to None.\n",
    "        selected_features_path (Path, optional): Path to selected features directory. Defaults to None.\n",
    "        random_seed (int, optional): Random seed for reproducibility. Defaults to 42.\n",
    "    Returns:\n",
    "        tuple: Contains paths and filenames for models, data, and other resources.\n",
    "    \"\"\"\n",
    "\n",
    "    csv_file = data_path / f\"prop_{case_number}eeg_Fp1Fp2.csv\"\n",
    "    propofol_concentration_blood_plasma = pd.read_csv(\n",
    "        base_path\n",
    "        / \"EEG_data\"\n",
    "        / \"propofol_infusion\"\n",
    "        / f\"prop{volunteer_number}Ce_Fp1Fp2.csv\"\n",
    "    )\n",
    "    csv_files_groundtruth = {\n",
    "        \"sleep\": data_path / f\"prop{volunteer_number}sleep_Fp1Fp2.csv\",\n",
    "        \"bs1sec\": data_path / f\"prop{volunteer_number}bs1sec_Fp1Fp2.csv\",\n",
    "        \"bs3sec\": data_path / f\"prop{volunteer_number}bs3sec_Fp1Fp2.csv\",\n",
    "        \"cr\": data_path / f\"prop{volunteer_number}cr_Fp1Fp2.csv\",\n",
    "        \"sspl\": data_path / f\"prop{volunteer_number}sspl_Fp1Fp2.csv\",\n",
    "    }\n",
    "    if number_of_selected_feature is not None:\n",
    "\n",
    "        model_filenames = {\n",
    "            \"sleep\": file_path\n",
    "            / f\"{strategy}_sleep_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['sleep']}_preprocTrue_randomseed{random_seed}_{number_of_selected_feature}.pkl\",\n",
    "            \"cr\": file_path\n",
    "            / f\"{strategy}_cr_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['cr']}_preprocTrue_randomseed{random_seed}_{number_of_selected_feature}.pkl\",\n",
    "            \"sspl\": file_path\n",
    "            / f\"{strategy}_sspl_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['sspl']}_preprocTrue_randomseed{random_seed}_{number_of_selected_feature}.pkl\",\n",
    "            \"burst_suppression\": file_path\n",
    "            / f\"{strategy}_burst_suppression_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['burst_suppression']}_preprocTrue_randomseed{random_seed}_{number_of_selected_feature}.pkl\",\n",
    "        }\n",
    "\n",
    "        selected_features_filename = {\n",
    "            \"sleep\": selected_features_path\n",
    "            / f\"Sleep_FeatureBased_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.json\",\n",
    "            \"cr\": selected_features_path\n",
    "            / f\"cr_FeatureBased_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.json\",\n",
    "            \"sspl\": selected_features_path\n",
    "            / f\"sspl_FeatureBased_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.json\",\n",
    "            \"burst_suppression\": selected_features_path\n",
    "            / f\"burst_suppression_FeatureBased_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.json\",\n",
    "        }\n",
    "        scaler_filenames = {\n",
    "            \"sleep\": scaler_path\n",
    "            / f\"FeatureBased_sleep_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.joblib\",\n",
    "            \"cr\": scaler_path\n",
    "            / f\"FeatureBased_cr_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.joblib\",\n",
    "            \"sspl\": scaler_path\n",
    "            / f\"FeatureBased_sspl_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.joblib\",\n",
    "            \"burst_suppression\": scaler_path\n",
    "            / f\"FeatureBased_burst_suppression_ws{window_size}_ss{step_size}_majority{majority}_preprocTrue_randomseed42_numfeatures{number_of_selected_feature}.joblib\",\n",
    "        }\n",
    "\n",
    "        return (\n",
    "            file_path,\n",
    "            csv_files_groundtruth,\n",
    "            model_filenames,\n",
    "            model_names,\n",
    "            selected_features_filename,\n",
    "            scaler_filenames,\n",
    "            csv_file,\n",
    "            propofol_concentration_blood_plasma,\n",
    "        )\n",
    "    else:\n",
    "        model_filenames = {\n",
    "            \"sleep\": file_path\n",
    "            / f\"{strategy}_sleep_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['sleep']}_preprocTrue_randomseed42_all.pt\",\n",
    "            \"cr\": file_path\n",
    "            / f\"{strategy}_cr_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['cr']}_preprocTrue_randomseed42_all.pt\",\n",
    "            \"sspl\": file_path\n",
    "            / f\"{strategy}_sspl_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['sspl']}_preprocTrue_randomseed42_all.pt\",\n",
    "            \"burst_suppression\": file_path\n",
    "            / f\"{strategy}_burst_suppression_ws{window_size}_ss{step_size}_majority{majority}_type{model_names['burst_suppression']}_preprocTrue_randomseed42_all.pt\",\n",
    "        }\n",
    "\n",
    "        return (\n",
    "            file_path,\n",
    "            csv_files_groundtruth,\n",
    "            model_filenames,\n",
    "            model_names,\n",
    "            None,\n",
    "            None,\n",
    "            csv_file,\n",
    "            propofol_concentration_blood_plasma,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Define which model you would like to run the inference for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    \"sleep\": \"RandomForestClassifier\",\n",
    "    \"cr\": \"RandomForestClassifier\",\n",
    "    \"sspl\": \"RandomForestClassifier\",\n",
    "    \"burst_suppression\": \"RandomForestClassifier\",\n",
    "}\n",
    "\n",
    "\"\"\" \n",
    "Further Examples:\n",
    "model_names = {\n",
    "    \"sleep\": \"TabICLClassifier\",\n",
    "    \"cr\":  \"TabICLClassifier\",\n",
    "    \"sspl\": \"TabICLClassifier\",\n",
    "    \"burst_suppression\":  \"TabICLClassifier\",\n",
    "}\n",
    "\n",
    "model_names = {\n",
    "    \"sleep\": \"TabularNN\",\n",
    "    \"cr\":  \"TabularNN\",\n",
    "    \"sspl\": \"TabularNN\",\n",
    "    \"burst_suppression\":\"TabularNN\",\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Run the Inference:\n",
    "\n",
    "- If you don't have any ground truths, you can run the inference, by putting inference_mode to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "(\n",
    "    file_path,\n",
    "    csv_files_groundtruth,\n",
    "    model_filenames,\n",
    "    model_names,\n",
    "    selected_features_filename,\n",
    "    scaler_filenames,\n",
    "    csv_file,\n",
    "    propofol_concentration_blood_plasma,\n",
    ") = define_file_paths(\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    majority=for_majority,\n",
    "    number_of_selected_feature=num_selected_features,\n",
    "    data_path=data_path,\n",
    "    file_path=file_path,\n",
    "    model_names=model_names,\n",
    "    selected_features_path=selected_features_path,\n",
    "    volunteer_number=volunteer_number,\n",
    "    case_number=case_number,\n",
    "    random_seed=random_seed,\n",
    ")\n",
    "inference = EEGInference(\n",
    "    csv_file=csv_file,\n",
    "    sampling_rate=sampling_rate,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    for_majority=for_majority,\n",
    "    preprocessing=preprocessing,\n",
    "    majority_voting=True,\n",
    "    strategy=strategy,\n",
    "    random_seed=random_seed,\n",
    "    feature_selection=feature_selection,\n",
    "    scaler_applicable=True,\n",
    "    device=\"cpu\",\n",
    "    inference_mode=False,\n",
    "    depth_of_anesthesia=True,\n",
    "    visualize_results=True,\n",
    "    csv_files_groundtruth=csv_files_groundtruth,\n",
    "    model_filenames=model_filenames,\n",
    "    model_names=model_names,\n",
    "    selected_features_filename=selected_features_filename,\n",
    "    scaler_filenames=scaler_filenames,\n",
    "    propofol_concentration_blood_plasma=propofol_concentration_blood_plasma,\n",
    "    zoomed_in=True,\n",
    ")\n",
    "end = time.perf_counter()\n",
    "print(f\"Final Execution time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: If you want to run local error analysis with LIME:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.1 Define/adjust your file paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"burst_suppression\"\n",
    "model_name = \"TabICLClassifier\"\n",
    "sample = 156 #Which window segment to choose.\n",
    "features = inference.features_processed\n",
    "predictions = inference.prediction\n",
    "utils = Utils(\n",
    "    for_majority=for_majority,\n",
    "    window_size=window_size,\n",
    "    step_size=step_size,\n",
    "    random_seed=random_seed,\n",
    "    preprocessing=preprocessing,\n",
    "    sampling_rate=sampling_rate,\n",
    "    results_validation_csv_path=base_path\n",
    "    / \"doA_classification\"\n",
    "    / \"ml_models\"\n",
    "    / f\"{strategy}_validation_results_df.csv\",\n",
    "    results_test_csv_path=base_path\n",
    "    / \"doA_classification\"\n",
    "    / \"ml_models\"\n",
    "    / f\"{strategy}_test_results_df.csv\",\n",
    "    model_dir=base_path / \"doA_classification\" / \"ml_models\",\n",
    ")\n",
    "\n",
    "base_path = Path.cwd()\n",
    "my_path = base_path.parent.parent.parent / \"Ablation\" / \"final\"\n",
    "model_path = (\n",
    "    my_path\n",
    "    / f\"FeatureBased_{label}_ws7680_ss7680_majority3840_typeTabICLClassifier_preprocTrue_randomseed42_50.pkl\"\n",
    ")\n",
    "selected_features_path = (\n",
    "    my_path\n",
    "    / f\"selected_features/{label}_FeatureBased_ws{window_size}_ss{step_size}_majority{for_majority}_preprocTrue_randomseed42_numfeatures50.json\"\n",
    ")\n",
    "scaler_filename = (\n",
    "    my_path\n",
    "    / \"scaler\"\n",
    "    / f\"FeatureBased_{label}_ws{window_size}_ss{step_size}_majority{for_majority}_preprocTrue_randomseed42_numfeatures50.joblib\"\n",
    ")\n",
    "training_data = pd.read_csv(\n",
    "    base_path / \"EEG_data\" / \"dataset\" / f\"training_data_{window_size}_{step_size}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Run LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model file for {model_path} not found.\")\n",
    "\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(\n",
    "    selected_features_path,\n",
    "    \"r\",\n",
    ") as f:\n",
    "    selected_feature_names = json.load(f)\n",
    "scaler = joblib.load(scaler_filename)\n",
    "\n",
    "X_train = training_data.loc[:, selected_feature_names]\n",
    "X_train = scaler.transform(X_train)\n",
    "pred = predictions.loc[:, selected_feature_names]\n",
    "X_test = scaler.transform(pred)\n",
    "X_train = np.nan_to_num(X_train, nan=0)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def predict_proba_lime(input_numpy, model):\n",
    "    \"\"\"Predict function for LIME that returns class probabilities.\n",
    "    Args:\n",
    "        input_numpy (np.ndarray): Input data for prediction.\n",
    "        model: Trained model\n",
    "    \"\"\"\n",
    " \n",
    "    if input_numpy.ndim == 1:\n",
    "        input_numpy = input_numpy.reshape(1, -1)\n",
    "\n",
    "    probs = model.predict_proba(input_numpy)\n",
    "\n",
    "    if probs.shape[1] == 1:\n",
    "        probs = np.hstack([1 - probs, probs])  \n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "pretty_feature_names = [\n",
    "    utils.feature_name_map.get(f, f) for f in selected_feature_names\n",
    "]\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_train, \n",
    "    mode=\"classification\",\n",
    "    feature_names=pretty_feature_names,\n",
    "    class_names=[\"no Burst Suppression\", \"Burst Suppression\"],\n",
    "    discretize_continuous=True,\n",
    ")\n",
    "features_new = pd.DataFrame(X_test)\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=features_new.iloc[sample].values,\n",
    "    predict_fn=lambda x: predict_proba_lime(x, model),\n",
    "    num_features=7,  # Number of features to display in explanation\n",
    ")\n",
    "\n",
    "exp.show_in_notebook(show_table=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
